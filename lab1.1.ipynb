{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fc06a1",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 \n",
    "## Проведение исследований с алгоритмом KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed703f0a",
   "metadata": {},
   "source": [
    "### 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0b545",
   "metadata": {},
   "source": [
    "#### a. Набор данных для задачи классификации\n",
    "\n",
    "Diabetes prediction dataset - https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset\n",
    "\n",
    "Набор данных для прогнозирования диабета представляет собой набор медицинских и демографических данных пациентов, включая информацию об их статусе диабета (положительный или отрицательный). Эти данные включают такие характеристики, как возраст, пол, индекс массы тела (ИМТ), гипертония, заболевания сердца, анамнез курения, уровень HbA1c и уровень глюкозы в крови. Этот набор данных может быть использован для построения моделей машинного обучения для прогнозирования диабета у пациентов на основе их истории болезни и демографической информации. Это может быть полезно медицинским работникам для выявления пациентов с потенциальным риском развития диабета и разработки индивидуальных планов лечения. Кроме того, этот набор данных может быть использован исследователями для изучения взаимосвязи между различными медицинскими и демографическими факторами и вероятностью развития диабета."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf66b1",
   "metadata": {},
   "source": [
    "#### b. Набор данных для задачи регрессии\n",
    "\n",
    "Honey purity dataset - https://www.kaggle.com/datasets/stealthtechnologies/predict-purity-and-price-of-honey\n",
    "\n",
    "Набор данных для прогнозирования качества и цены мёда. Решение данной задачи будет полезно пчеловодам для контроля качества их продукции и обоснования ее цены.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288af47",
   "metadata": {},
   "source": [
    "#### c. Выбор метрик качества\n",
    "\n",
    "##### Задача классификации:\n",
    "\n",
    "1) $Fbeta-score$ - основная метрика. Т.к. классы несбалансированы (здоровых людей больше чем, больных диабетом), то accuracy может быть обманчивой. $Fbeta-score$ учитывает $precision$ и $recall$, что подходит для медицинской диагностики, где важно найти найти как можно больше больных (высокий $recall$), но при этом не напугать здоровых (высокий $precision$). Дает больший вес $recall$ метрике при возрастании $beta$. $beta = 1,2,3, ...$\n",
    "\n",
    "2) $Recall$ - показывает сколько из всех рельно больных мы нашли.\n",
    "\n",
    "3) $Precision$ - показывает сколько из всех предсказанных больных действительно больны.\n",
    "\n",
    "4) $Accuracy$ - дополнительная метрика для общего понимания доли верных ответов.\n",
    "\n",
    "##### Задача регрессии:\n",
    "\n",
    "1) $MAE$ - показывает среднюю абсолютную ошибку в условных ед. Легко интерпретируется (В среднем модель ошибается на N у.е.).\n",
    "\n",
    "2) $RMSE$ - более строгая метрика, которая сильнее штрафует за большие ошибки предсказания.\n",
    "\n",
    "3) $R^2$ - показывает насколько модель предсказывает лучше, чем среднее значение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0977b7",
   "metadata": {},
   "source": [
    "### 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e2a62",
   "metadata": {},
   "source": [
    "#### 2.1. Обучение моделей из sklearn для решения задачи классификации и оценка качества по выбранным метрикам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c18279",
   "metadata": {},
   "source": [
    "0. Подключим необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f50cf",
   "metadata": {},
   "source": [
    "1. Загрузим датасет и посмотрим, что он из себя представляет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d93d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"datasets/diabetes_prediction_dataset.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e08aba",
   "metadata": {},
   "source": [
    "Посмотрим информацию о датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b778924",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes_df.info())\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae54c47",
   "metadata": {},
   "source": [
    "Посмотрим сколько у нас null столбцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4f5fa",
   "metadata": {},
   "source": [
    "Посмотрим сколько у нас повторяющихся строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd08ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a959cf",
   "metadata": {},
   "source": [
    "Посмотрим информацию о категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f357789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes_df['gender'].value_counts())\n",
    "print(diabetes_df['smoking_history'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bdc3d2",
   "metadata": {},
   "source": [
    "2. Сделаем минимально необходимую обработку и обучим модели: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dummies = pd.get_dummies(diabetes_df['gender'], drop_first=True)\n",
    "smoking_history_dummies = pd.get_dummies(diabetes_df['smoking_history'], drop_first=True)\n",
    "onehot_diabetes_df = pd.concat([diabetes_df, gender_dummies, smoking_history_dummies], axis=1)\n",
    "\n",
    "onehot_diabetes_df.drop(['gender', 'smoking_history'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6ad54",
   "metadata": {},
   "source": [
    "Разделим датафрейм на features и target, а также train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X = onehot_diabetes_df.drop('diabetes', axis=1)\n",
    "diabetes_y = onehot_diabetes_df['diabetes']\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(\n",
    "    diabetes_X,\n",
    "    diabetes_y,\n",
    "    test_size=0.2,\n",
    "    stratify=diabetes_y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef067939",
   "metadata": {},
   "source": [
    "Кросс-валидация и выбор лучшей модели по fbeta-score (beta = 1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "def find_optimal_threshhold_cv(model, X, y, cv=5, f_beta=1, eps=1e-9, report=False):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    thresholds = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        fold_model = clone(model)\n",
    "        fold_model.fit(X_train, y_train)\n",
    "        models.append(fold_model)\n",
    "        \n",
    "        y_prob_val = fold_model.predict_proba(X_val)[:, 1]\n",
    "        prec, rec, thresh = precision_recall_curve(y_val, y_prob_val)\n",
    "        f_beta_scores = (1 + f_beta ** 2) * (prec * rec) / ((f_beta ** 2 * prec) + rec + eps)\n",
    "        optimal_thresh_fold = thresh[f_beta_scores.argmax()]\n",
    "        thresholds.append(optimal_thresh_fold)\n",
    "        \n",
    "        y_pred_val = (y_prob_val >= optimal_thresh_fold).astype(int)\n",
    "        fold_scores.append({\n",
    "            'classification_report': classification_report(y_val, y_pred_val),\n",
    "            'f1_score': fbeta_score(y_val, y_pred_val, beta=1),\n",
    "            'f2_score': fbeta_score(y_val, y_pred_val, beta=2),\n",
    "            'f3_score': fbeta_score(y_val, y_pred_val, beta=3),\n",
    "            'f_beta_score': fbeta_score(y_val, y_pred_val, beta=f_beta)\n",
    "        })\n",
    "    \n",
    "    best_fold_idx = np.argmax([f['f_beta_score'] for f in fold_scores])\n",
    "    best_model = models[best_fold_idx]\n",
    "    best_threshold = thresholds[best_fold_idx]\n",
    "    best_fold_score = fold_scores[best_fold_idx]\n",
    "    \n",
    "    if report:        \n",
    "        print(f\"\\n=== Best Model f{f_beta} on validation ===\")\n",
    "        print(f\"Best fold: {best_fold_idx + 1}\")\n",
    "        print(best_fold_score['classification_report'])\n",
    "        print(f\"Best f1-score: {best_fold_score['f1_score']:.4f}\")\n",
    "        print(f\"Best f2-score: {best_fold_score['f2_score']:.4f}\")\n",
    "        print(f\"Best f3-score: {best_fold_score['f3_score']:.4f}\")\n",
    "        print(f\"Best f{f_beta}-score: {best_fold_score['f_beta_score']:.4f}\")\n",
    "        print(f\"Best threshold: {best_threshold}\")\n",
    "    \n",
    "    return best_model, best_threshold, best_fold_score\n",
    "    \n",
    "\n",
    "optimal_models = {}      \n",
    "optimal_thresholds = {}\n",
    "optimal_fold_scores = {}\n",
    "\n",
    "for f_score in [1, 2, 3]:\n",
    "    optimal_models[f'f{f_score}'], optimal_thresholds[f'f{f_score}'], optimal_fold_scores[f'f{f_score}'] = find_optimal_threshhold_cv(\n",
    "        model,\n",
    "        diabetes_X_train,\n",
    "        diabetes_y_train,\n",
    "        cv=5,\n",
    "        f_beta=f_score,\n",
    "        report=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bdd050",
   "metadata": {},
   "source": [
    "Проведем замеры на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_score in [1, 2, 3]:\n",
    "    model = optimal_models[f'f{f_score}']\n",
    "    threshold = optimal_thresholds[f'f{f_score}']\n",
    "    \n",
    "    y_prob_test = model.predict_proba(diabetes_X_test)[:, 1]\n",
    "    y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== Test Model f{f_score} ===\")\n",
    "    print(classification_report(diabetes_y_test, y_pred_test))\n",
    "    print(f\"f1-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=1):.4f}\")\n",
    "    print(f\"f2-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=2):.4f}\")\n",
    "    print(f\"f3-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=3):.4f}\")\n",
    "    print(f\"f{f_score}-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=f_score):.4f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ccadc",
   "metadata": {},
   "source": [
    "Вывод: несмотря на неплохой accuracy от 0.89 до 0.95 в зависимости от метрики, которую мы хотим оптимизировать. Видно следующее при вменяемом precision = 0.88 для определения класса \"есть диабет\", recall очень низкий. При стремлении увеличить recall начинает страдать precision, причем очень сильно. Это более заметно для класса \"есть диабет\", т.к. таких значений в разы меньше. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de582004",
   "metadata": {},
   "source": [
    "### 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290fffe",
   "metadata": {},
   "source": [
    "#### 3.1. Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43cf9a9",
   "metadata": {},
   "source": [
    "0. Подключение модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0380c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b93b6d",
   "metadata": {},
   "source": [
    "1. Проведем более детальный анализ датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb47bc",
   "metadata": {},
   "source": [
    "Вспомним, что из себя представляет датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество строк: {diabetes_df.shape[0]}, столбцев {diabetes_df.shape[1]}\")\n",
    "print(diabetes_df.info(), diabetes_df.describe())\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2499a9",
   "metadata": {},
   "source": [
    "Посмотрим сколько значений пропущено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac76f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fecd5",
   "metadata": {},
   "source": [
    "Какие есть уникальные категориальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes_df['gender'].value_counts())\n",
    "print(diabetes_df['smoking_history'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa104f",
   "metadata": {},
   "source": [
    "Построим графики распределения всех людей и тех у кого диабет.\n",
    "\n",
    "Синий - нет диабета.\n",
    "\n",
    "Красный - есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "all_features = ['gender', 'age', 'hypertension', 'heart_disease', \n",
    "                'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "for i, feature in enumerate(all_features, 1):\n",
    "    plt.subplot(4, 2, i)\n",
    "    \n",
    "    if feature in ['gender', 'smoking_history']:  # Категориальные признаки\n",
    "        cross_tab = pd.crosstab(diabetes_df[feature], diabetes_df['diabetes'], normalize='index') * 100\n",
    "        cross_tab.plot(kind='bar', ax=plt.gca(), color=['skyblue', 'salmon'])\n",
    "        plt.title(f'Распределение диабета по {feature}')\n",
    "        plt.ylabel('Процент (%)')\n",
    "        plt.legend(['Нет диабета', 'Диабет'])\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "    elif feature in ['hypertension', 'heart_disease']:  # Бинарные признаки\n",
    "        sns.countplot(data=diabetes_df, x=feature, hue='diabetes', palette=['skyblue', 'salmon'])\n",
    "        plt.title(f'Диабет по {feature}')\n",
    "        plt.legend(['Нет диабета', 'Диабет'])\n",
    "        \n",
    "    else:  # Числовые признаки\n",
    "        sns.boxplot(data=diabetes_df, x='diabetes', y=feature, palette=['skyblue', 'salmon'], hue='diabetes')\n",
    "        plt.title(f'Распределение {feature} по диабету')\n",
    "        plt.xlabel('Диабет (0-нет, 1-да)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de6377",
   "metadata": {},
   "source": [
    "Из графика рапределения bmi явно видны выбросы. Их необходимо будет почистить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ae2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr_by_group(df, column, group_column):\n",
    "    df_clean = df.copy()\n",
    "    for group in df[group_column].unique():\n",
    "        group_data = df[df[group_column] == group]\n",
    "        Q1 = group_data[column].quantile(0.25)\n",
    "        Q3 = group_data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_mask = (df_clean[group_column] == group) & (\n",
    "            (df_clean[column] < lower_bound) | (df_clean[column] > upper_bound)\n",
    "        )\n",
    "        df_clean = df_clean[~outliers_mask]\n",
    "    return df_clean\n",
    "\n",
    "diabetes_clean = remove_outliers_iqr_by_group(diabetes_df, 'bmi', 'diabetes')\n",
    "diabetes_clean.shape, diabetes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe93749",
   "metadata": {},
   "source": [
    "Посмотрим как прошли изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=diabetes_clean, x='diabetes', y='bmi', palette=['skyblue', 'salmon'], hue='diabetes')\n",
    "plt.title('Распределение bmi по диабету')\n",
    "plt.xlabel('Диабет (0-нет, 1-да)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c714e6",
   "metadata": {},
   "source": [
    "Построим матрицу корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c49275",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "binary_features = ['hypertension', 'heart_disease']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = diabetes_clean[numeric_features + binary_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Матрица корреляций', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f0667",
   "metadata": {},
   "source": [
    "Построим графику зависимости между числовыми признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(diabetes_clean[binary_features + numeric_features + ['diabetes']].sample(n=5000, random_state=42),\n",
    "             hue='diabetes', palette=['skyblue', 'salmon'],\n",
    "             diag_kind='kde', plot_kws={'alpha': 0.7, 's': 30})\n",
    "plt.suptitle('Pairplot: Зависимости между числовыми признаками', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae242c",
   "metadata": {},
   "source": [
    "Создадим новые фичи на основе числовых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_num_features(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    new_df['log(age*bmi*HbA1c_level*blood_glucose_level+1)'] = np.log(new_df['age'] * new_df['bmi'] * new_df['HbA1c_level'] * new_df['blood_glucose_level'] + 1)\n",
    "\n",
    "    new_df['age*bmi'] = new_df['age'] * new_df['bmi']\n",
    "    new_df['HbA1c_levelxblood_glucose_level'] = new_df['HbA1c_level'] * new_df['blood_glucose_level']\n",
    "    new_df['bmi*blood_glucose_level'] = new_df['bmi'] * new_df['blood_glucose_level']\n",
    "\n",
    "    new_df['bmi*HbA1c_level*blood_glucose_level'] = new_df['bmi'] * new_df['HbA1c_level'] * new_df['blood_glucose_level']\n",
    "\n",
    "    new_df['bmi/age'] = new_df['bmi'] / (new_df['age'] + 1e-6)\n",
    "    new_df['blood_glucose_level/HbA1c_level'] = new_df['blood_glucose_level'] / (new_df['HbA1c_level'] + 1e-6)\n",
    "    new_df['blood_glucose_level/age'] = new_df['blood_glucose_level'] / new_df['age']\n",
    "\n",
    "\n",
    "    new_df['bmi^2'] = new_df['bmi'] ** 2\n",
    "    new_df['HbA1c_level^2'] = new_df['HbA1c_level'] ** 2\n",
    "    new_df['blood_glucose_level^2'] = new_df['blood_glucose_level'] ** 2\n",
    "\n",
    "    new_df['log_blood_glucose_level+1'] = np.log(new_df['blood_glucose_level'] + 1)\n",
    "    new_df['log_HbA1c_level+1'] = np.log(new_df['HbA1c_level'] + 1)\n",
    "    new_df['log_bmi+1'] = np.log(new_df['bmi'] + 1)\n",
    "\n",
    "    new_df['age_z'] = (new_df['age'] - new_df['age'].mean()) / new_df['age'].std()\n",
    "    new_df['bmi_z'] = (new_df['bmi'] - new_df['bmi'].mean()) / new_df['bmi'].std()\n",
    "    new_df['HbA1c_level_z'] = (new_df['HbA1c_level'] - new_df['HbA1c_level'].mean()) / new_df['HbA1c_level'].std()\n",
    "    new_df['blood_glucose_level_z'] = (new_df['blood_glucose_level'] - new_df['blood_glucose_level'].mean()) / new_df['blood_glucose_level'].std()\n",
    "\n",
    "    new_df['risk_index'] = (new_df['age_z'] + new_df['bmi_z'] + new_df['HbA1c_level_z'] + new_df['blood_glucose_level_z']) / 4\n",
    "    \n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c297fd8",
   "metadata": {},
   "source": [
    "Теперь поработаем с историей курения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae06fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes_clean['smoking_history'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0822d9c",
   "metadata": {},
   "source": [
    "\"No Info\" - Информация отсутствует (пропущенные данные)\n",
    "\n",
    "\"never\" - Никогда не курил\n",
    "\n",
    "\"former\" - Бывший курильщик\n",
    "\n",
    "\"current\" - Текущий курильщик\n",
    "\n",
    "\"not current\" - В настоящее время не курит (похоже на \"former\")\n",
    "\n",
    "\"ever\" - Когда-либо курил (похоже на \"former\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a4b60",
   "metadata": {},
   "source": [
    "Поэтому закодирую следующим образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf420f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smoking_features(df):\n",
    "    new_df = df.copy()\n",
    "    mapping = {\n",
    "        'No Info': np.nan,\n",
    "        'never': 0,\n",
    "        'former': 1,\n",
    "        'current': 2,\n",
    "        'not current': 1,\n",
    "        'ever': 1\n",
    "    }\n",
    "\n",
    "    new_df['smoking_history_encoded'] = (\n",
    "        new_df['smoking_history']\n",
    "        .map(mapping)\n",
    "        .fillna(new_df['smoking_history'].map(mapping).mean())\n",
    "    )\n",
    "    new_df = new_df.drop('smoking_history', axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e327b",
   "metadata": {},
   "source": [
    "Также сделаем обработку gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7171d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes_clean['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb74aa0",
   "metadata": {},
   "source": [
    "Other заменим на среднее значение и сделаем новый признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gender_features(df):\n",
    "    new_df = df.copy()\n",
    "    mapping = {\n",
    "        'Other': np.nan,\n",
    "        'Male': 1,\n",
    "        'Female': 0\n",
    "    }\n",
    "\n",
    "    new_df['gender_encoded'] = (\n",
    "        df['gender']\n",
    "        .map(mapping)\n",
    "        .fillna(df['gender'].map(mapping).mean())\n",
    "    )\n",
    "    \n",
    "    new_df = new_df.drop('gender', axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5b819",
   "metadata": {},
   "source": [
    "Добавим еще несколько бинарных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['hypertension*glucose'] = new_df['hypertension'] * new_df['blood_glucose_level']\n",
    "    new_df['heart_disease*HbA1c_level'] = new_df['heart_disease'] * new_df['HbA1c_level']\n",
    "    new_df['overweighted'] = (new_df['bmi'] > 25).astype(int)\n",
    "    new_df['obese'] = (new_df['bmi'] > 30).astype(int)\n",
    "    new_df['young'] = (new_df['age'] < 30).astype(int)\n",
    "    new_df['elder'] = (new_df['age'] >= 60).astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc571694",
   "metadata": {},
   "source": [
    "Медицинские показатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_medical_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['metabolic_syndrome'] = (new_df['bmi'] > 30).astype(int) + new_df['hypertension'] + new_df['heart_disease']\n",
    "    new_df['heart_diseaseORhypertension'] = (new_df['heart_disease'] | new_df['hypertension']).astype(int)\n",
    "    new_df['high_HbA1c_level'] = (new_df['HbA1c_level'] > 6).astype(int)\n",
    "    new_df['high_blood_glucose_level'] = (new_df['blood_glucose_level'] > 125).astype(int)\n",
    "    new_df['normal_blood_glucose_level'] = (new_df['blood_glucose_level'] < 100).astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f315c58",
   "metadata": {},
   "source": [
    "Создать все features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df = create_num_features(new_df)\n",
    "    new_df = create_smoking_features(new_df)\n",
    "    new_df = create_gender_features(new_df)\n",
    "    new_df = create_binary_features(new_df)\n",
    "    new_df = create_medical_features(new_df)\n",
    "    return new_df\n",
    "\n",
    "diabetes_new_features = create_features(diabetes_clean)\n",
    "diabetes_new_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b0dcf",
   "metadata": {},
   "source": [
    "Построим матрицу корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['overweighted', 'obese', 'young', 'elder', 'heart_diseaseORhypertension', 'high_HbA1c_level', 'high_blood_glucose_level', 'normal_blood_glucose_level',\n",
    "                'log(age*bmi*HbA1c_level*blood_glucose_level+1)', 'age*bmi', 'HbA1c_levelxblood_glucose_level', 'bmi*blood_glucose_level', 'bmi*HbA1c_level*blood_glucose_level',\n",
    "                'bmi/age', 'blood_glucose_level/HbA1c_level', 'blood_glucose_level/age', 'bmi^2', 'HbA1c_level^2', 'blood_glucose_level^2', 'log_blood_glucose_level+1', 'log_HbA1c_level+1', 'log_bmi+1',\n",
    "                'hypertension*glucose', 'heart_disease*HbA1c_level', 'smoking_history_encoded', 'gender_encoded', 'metabolic_syndrome']\n",
    "\n",
    "old_features = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'hypertension', 'heart_disease', 'diabetes']\n",
    "\n",
    "\n",
    "corr_matrix = diabetes_new_features[new_features + old_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "plt.title('Матрица корреляций', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509a1b3",
   "metadata": {},
   "source": [
    "Уменьшим мультиколлинеарность и упростим модель. Для этого удалю числовые признаки, которые имеют высокую корреляцию с другими. Исключу признаки с корреляцией Пирсона выше порогового значения = 0,95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_correlated_features(df, threshold=0.95):\n",
    "    df_clean = df.copy()\n",
    "    corr_matrix = df_clean.corr().abs()\n",
    "    upper_triangle = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "    high_corr_pairs = np.where((corr_matrix > threshold) & upper_triangle)\n",
    "    to_drop = set()\n",
    "    for i, j in zip(*high_corr_pairs):\n",
    "        feature_i = corr_matrix.columns[i]\n",
    "        feature_j = corr_matrix.columns[j]\n",
    "        if corr_matrix[feature_i].mean() > corr_matrix[feature_j].mean():\n",
    "            to_drop.add(feature_j)\n",
    "        else:\n",
    "            to_drop.add(feature_i)\n",
    "    df_clean = df_clean.drop(columns=to_drop)\n",
    "    return df_clean\n",
    "\n",
    "diabetes_new_features = drop_highly_correlated_features(diabetes_new_features[new_features + old_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba573f52",
   "metadata": {},
   "source": [
    "Поссмотрим, что сейчас представляет из себя матрица корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = diabetes_new_features.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0)\n",
    "plt.title('Матрица корреляций', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ae512",
   "metadata": {},
   "source": [
    "Посмортим на результат после создания новых фич"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ada6a7",
   "metadata": {},
   "source": [
    "Для начала снова подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Разделим выборки на train и test,\n",
    "# Но т.к. нужно удалить выбросы только, для train выборки, то делаем:\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "diabetes_X = diabetes_df.drop('diabetes', axis=1)\n",
    "diabetes_y = diabetes_df['diabetes']\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(\n",
    "    diabetes_X,\n",
    "    diabetes_y,\n",
    "    test_size=0.2,\n",
    "    stratify=diabetes_y,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "diabetes_train_df = pd.DataFrame(diabetes_X_train, columns=diabetes_X.columns)\n",
    "diabetes_train_df['diabetes'] = diabetes_y_train\n",
    "\n",
    "diabetes_test_df = pd.DataFrame(diabetes_X_test, columns=diabetes_X.columns)\n",
    "diabetes_test_df['diabetes'] = diabetes_y_test\n",
    "\n",
    "# Удалим выбросы только для train\n",
    "diabetes_train_df = remove_outliers_iqr_by_group(diabetes_train_df, 'bmi', 'diabetes')\n",
    "\n",
    "# Создаем фичи\n",
    "diabetes_train_df = create_features(diabetes_train_df)\n",
    "diabetes_test_df = create_features(diabetes_test_df)\n",
    "\n",
    "# Удалим features, которые имеют высокую корреляцию с другими\n",
    "diabetes_train_df = drop_highly_correlated_features(diabetes_train_df)\n",
    "diabetes_test_df = diabetes_test_df[diabetes_train_df.columns]\n",
    "\n",
    "# Снова отделим target от всех остальных данных\n",
    "diabetes_X_train = diabetes_train_df.drop('diabetes', axis=1)\n",
    "diabetes_y_train = diabetes_train_df['diabetes']\n",
    "\n",
    "diabetes_X_test = diabetes_test_df.drop('diabetes', axis=1)\n",
    "diabetes_y_test = diabetes_test_df['diabetes']\n",
    "\n",
    "# Применим RobustScaler, т.к. он устойчив к выбросам\n",
    "scaler = RobustScaler()\n",
    "diabetes_X_train = pd.DataFrame(scaler.fit_transform(diabetes_X_train), columns=diabetes_X_train.columns)\n",
    "diabetes_X_test = pd.DataFrame(scaler.transform(diabetes_X_test), columns=diabetes_X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030edb5b",
   "metadata": {},
   "source": [
    "Кросс-валидация и выбор лучшей модели по fbeta-score (beta = 1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3128de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "\n",
    "def find_best_hyperparameters_cv(X, y, n_trials=10, cv=5, scoring='accuracy', n_jobs=-1):\n",
    "    def objective(trial):\n",
    "        n_neighbors = trial.suggest_int('n_neighbors', 3, 15)\n",
    "        weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "        p = trial.suggest_int('p', 1, 3)\n",
    "        metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "        \n",
    "        model = KNeighborsClassifier(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            p=p,\n",
    "            metric=metric,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        \n",
    "        return cross_val_score(model, X, y, cv=cv, scoring=scoring).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'f1' : {'n_neighbors': 7, 'weights': 'uniform', 'p': 2, 'metric': 'manhattan'},\n",
    "    'f2' : {'n_neighbors': 4, 'weights': 'distance', 'p': 1, 'metric': 'euclidean'},\n",
    "    'f3' : {'n_neighbors': 3, 'weights': 'distance', 'p': 3, 'metric': 'manhattan'}\n",
    "}\n",
    "\n",
    "for beta in [1, 2, 3]:\n",
    "    scorer = make_scorer(fbeta_score, beta=beta) \n",
    "    if not best_params.get(f'f{beta}'):\n",
    "        best_params[f'f{beta}'] = find_best_hyperparameters_cv(\n",
    "            diabetes_X_train,\n",
    "            diabetes_y_train,\n",
    "            n_trials=10,\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            scoring=scorer\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n=== Best Model f{beta} on validation ===\")\n",
    "    print(f\"Best params: {best_params[f'f{beta}']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36109f2b",
   "metadata": {},
   "source": [
    "Подберем оптимальный threshold для каждой из моделей и каждой из fbeta метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_models = {}      \n",
    "optimal_thresholds = {}\n",
    "optimal_fold_scores = {}\n",
    "\n",
    "for beta in [1, 2, 3]:\n",
    "    for model_name in [1, 2, 3]:\n",
    "        model = KNeighborsClassifier(**best_params[f'f{model_name}'])\n",
    "        \n",
    "        model, threshold, fold_score = find_optimal_threshhold_cv(\n",
    "            model,\n",
    "            diabetes_X_train,\n",
    "            diabetes_y_train,\n",
    "            cv=5,\n",
    "            f_beta=beta,\n",
    "            report=True\n",
    "        )\n",
    "        if optimal_models.get(f'f{beta}'):\n",
    "            if fold_score['f_beta_score'] > optimal_fold_scores[f'f{beta}']['f_beta_score']:\n",
    "                optimal_models[f'f{beta}'] = model\n",
    "                optimal_thresholds[f'f{beta}'] = threshold\n",
    "                optimal_fold_scores[f'f{beta}'] = fold_score\n",
    "        else:\n",
    "            optimal_models[f'f{beta}'] = model\n",
    "            optimal_thresholds[f'f{beta}'] = threshold\n",
    "            optimal_fold_scores[f'f{beta}'] = fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadfdc3",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ef7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [1, 2, 3]:\n",
    "    print(optimal_fold_scores[f'f{beta}']['classification_report'])\n",
    "    print(f\"Best f{beta}-score: {optimal_fold_scores[f'f{beta}']['f_beta_score']:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49969a95",
   "metadata": {},
   "source": [
    "Проведем замеры на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [1, 2, 3]:\n",
    "    model = optimal_models[f'f{beta}']\n",
    "    threshold = optimal_thresholds[f'f{beta}']\n",
    "    \n",
    "    y_prob_test = model.predict_proba(diabetes_X_test)[:, 1]\n",
    "    y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== Test Model f{beta} ===\")\n",
    "    print(classification_report(diabetes_y_test, y_pred_test))\n",
    "    print(f\"f1-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=1):.4f}\")\n",
    "    print(f\"f2-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=2):.4f}\")\n",
    "    print(f\"f3-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=3):.4f}\")\n",
    "    print(f\"f{beta}-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=beta):.4f}\")\n",
    "    print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c256cc6",
   "metadata": {},
   "source": [
    "Вывод: улучшения повысили детекцию класса 1 (есть диабет), особенно recall. Лучший баланс между precision и recall показывает модель, где оптимизировалась метрика f1. Однако если нам нужно найти всех реально больных, то лучше использовать модель, где оптимизировалась метрика f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edebd0a",
   "metadata": {},
   "source": [
    "### 4.  Имплементация алгоритма машинного обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa925c7e",
   "metadata": {},
   "source": [
    "4.1. Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.neighbors import BallTree, KDTree\n",
    "\n",
    "\n",
    "class LabKNeighborsClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors=5, weights='uniform', \n",
    "                 p=2, metric='minkowski', n_jobs=None, \n",
    "                 leaf_size=30, algorithm='auto'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.p = p\n",
    "        self.metric = metric\n",
    "        self.n_jobs = n_jobs\n",
    "        self.leaf_size = leaf_size\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "        self.kd_tree_metrics = {\n",
    "            'euclidean', 'manhattan', 'chebyshev', 'minkowski',\n",
    "            'cityblock', 'l1', 'l2', 'infinity'\n",
    "        }\n",
    "        \n",
    "        self.ball_tree_metrics = {\n",
    "            'cosine', 'haversine', 'hamming', \n",
    "            'jaccard', 'dice', 'matching',\n",
    "            'mahalanobis', 'seuclidean', 'wminkowski'\n",
    "        }\n",
    "        \n",
    "        self.brute_only_metrics = {\n",
    "            'canberra', 'braycurtis', 'correlation', 'sqeuclidean',\n",
    "            'kulsinski', 'rogerstanimoto', 'russellrao', 'sokalmichener',\n",
    "            'sokalsneath', 'yule'\n",
    "        }\n",
    "    \n",
    "    def _select_algorithm(self):\n",
    "        if self.algorithm != 'auto':\n",
    "            return self.algorithm\n",
    "            \n",
    "        if self.metric in self.brute_only_metrics:\n",
    "            return 'brute'\n",
    "            \n",
    "        if self.metric in self.kd_tree_metrics:\n",
    "            if self.metric == 'minkowski':\n",
    "                if self.p == 1 or self.p == 2 or self.p == np.inf:\n",
    "                    return 'kd_tree'\n",
    "                else:\n",
    "                    return 'ball_tree'\n",
    "            return 'kd_tree'\n",
    "        elif self.metric in self.ball_tree_metrics:\n",
    "            return 'ball_tree'\n",
    "        else:\n",
    "            return 'brute'\n",
    "    \n",
    "    def _compute_distance(self, x1, x2):\n",
    "        if self.metric == 'euclidean' or self.metric == 'l2':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.metric == 'manhattan' or self.metric == 'cityblock' or self.metric == 'l1':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        elif self.metric == 'chebyshev' or self.metric == 'infinity':\n",
    "            return np.max(np.abs(x1 - x2))\n",
    "        elif self.metric == 'minkowski':\n",
    "            return np.power(np.sum(np.power(np.abs(x1 - x2), self.p)), 1/self.p)\n",
    "        elif self.metric == 'cosine':\n",
    "            dot_product = np.dot(x1, x2)\n",
    "            norm1 = np.linalg.norm(x1)\n",
    "            norm2 = np.linalg.norm(x2)\n",
    "            return 1 - dot_product / (norm1 * norm2 + 1e-10)\n",
    "        elif self.metric == 'hamming':\n",
    "            return np.mean(x1 != x2)\n",
    "        elif self.metric == 'sqeuclidean':\n",
    "            return np.sum((x1 - x2) ** 2)\n",
    "        elif self.metric == 'canberra':\n",
    "            numerator = np.abs(x1 - x2)\n",
    "            denominator = np.abs(x1) + np.abs(x2)\n",
    "            return np.sum(np.divide(numerator, denominator, \n",
    "                                   out=np.zeros_like(numerator), \n",
    "                                   where=denominator!=0))\n",
    "        elif self.metric == 'braycurtis':\n",
    "            return np.sum(np.abs(x1 - x2)) / np.sum(np.abs(x1 + x2))\n",
    "        else:\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def _brute_neighbors(self, X_query, n_neighbors=None):\n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "        \n",
    "        n_query = X_query.shape[0]\n",
    "        n_train = self.X_.shape[0]\n",
    "        \n",
    "        distances = np.zeros((n_query, n_train))\n",
    "        \n",
    "        for i in range(n_query):\n",
    "            if self.metric == 'euclidean' or self.metric == 'l2':\n",
    "                distances[i, :] = np.sqrt(np.sum((self.X_ - X_query[i]) ** 2, axis=1))\n",
    "            elif self.metric == 'manhattan' or self.metric == 'cityblock' or self.metric == 'l1':\n",
    "                distances[i, :] = np.sum(np.abs(self.X_ - X_query[i]), axis=1)\n",
    "            elif self.metric == 'chebyshev' or self.metric == 'infinity':\n",
    "                distances[i, :] = np.max(np.abs(self.X_ - X_query[i]), axis=1)\n",
    "            elif self.metric == 'minkowski':\n",
    "                distances[i, :] = np.power(\n",
    "                    np.sum(np.power(np.abs(self.X_ - X_query[i]), self.p), axis=1),\n",
    "                    1/self.p\n",
    "                )\n",
    "            elif self.metric == 'cosine':\n",
    "                dot_products = np.dot(self.X_, X_query[i])\n",
    "                norms_X = np.linalg.norm(self.X_, axis=1)\n",
    "                norm_query = np.linalg.norm(X_query[i])\n",
    "                distances[i, :] = 1 - dot_products / (norms_X * norm_query + 1e-10)\n",
    "            elif self.metric == 'sqeuclidean':\n",
    "                distances[i, :] = np.sum((self.X_ - X_query[i]) ** 2, axis=1)\n",
    "            else:\n",
    "                for j in range(n_train):\n",
    "                    distances[i, j] = self._compute_distance(X_query[i], self.X_[j])\n",
    "        \n",
    "        if n_neighbors == 1:\n",
    "            indices = np.argmin(distances, axis=1).reshape(-1, 1)\n",
    "            neighbor_distances = np.min(distances, axis=1).reshape(-1, 1)\n",
    "        else:\n",
    "            partition_indices = np.argpartition(distances, n_neighbors, axis=1)[:, :n_neighbors]\n",
    "\n",
    "            indices = np.zeros((n_query, n_neighbors), dtype=int)\n",
    "            neighbor_distances = np.zeros((n_query, n_neighbors))\n",
    "            \n",
    "            for i in range(n_query):\n",
    "                k_distances = distances[i, partition_indices[i]]\n",
    "                \n",
    "                sorted_k_indices = np.argsort(k_distances)\n",
    "                \n",
    "                indices[i] = partition_indices[i][sorted_k_indices]\n",
    "                neighbor_distances[i] = k_distances[sorted_k_indices]\n",
    "        \n",
    "        return neighbor_distances, indices\n",
    "    \n",
    "    def _build_tree(self, X):\n",
    "        selected_algorithm = self._select_algorithm()\n",
    "        \n",
    "        if selected_algorithm == 'kd_tree':\n",
    "            try:\n",
    "                if self.metric == 'manhattan' or self.metric == 'l1':\n",
    "                    metric_name = 'cityblock'\n",
    "                    tree_kwargs = {'p': 1} if self.metric == 'minkowski' else {}\n",
    "                elif self.metric == 'euclidean' or self.metric == 'l2':\n",
    "                    metric_name = 'euclidean'\n",
    "                    tree_kwargs = {'p': 2} if self.metric == 'minkowski' else {}\n",
    "                elif self.metric == 'chebyshev' or self.metric == 'infinity':\n",
    "                    metric_name = 'chebyshev'\n",
    "                    tree_kwargs = {}\n",
    "                elif self.metric == 'minkowski':\n",
    "                    metric_name = 'minkowski'\n",
    "                    tree_kwargs = {'p': self.p}\n",
    "                else:\n",
    "                    metric_name = self.metric\n",
    "                    tree_kwargs = {}\n",
    "                \n",
    "                if tree_kwargs:\n",
    "                    self.tree_ = KDTree(X, leaf_size=self.leaf_size, \n",
    "                                       metric=metric_name, **tree_kwargs)\n",
    "                else:\n",
    "                    self.tree_ = KDTree(X, leaf_size=self.leaf_size, \n",
    "                                       metric=metric_name)\n",
    "                    \n",
    "                self.tree_type_ = 'kd_tree'\n",
    "                \n",
    "            except (ValueError, TypeError) as e:\n",
    "                print(f\"KDTree не поддерживает метрику {self.metric} с параметрами: {e}\")\n",
    "                print(\"Пробуем BallTree...\")\n",
    "                selected_algorithm = 'ball_tree'\n",
    "        \n",
    "        if selected_algorithm == 'ball_tree' or (selected_algorithm == 'kd_tree' and not hasattr(self, 'tree_')):\n",
    "            try:\n",
    "                if self.metric == 'manhattan' or self.metric == 'l1':\n",
    "                    metric_name = 'cityblock'\n",
    "                    tree_kwargs = {'p': 1} if self.metric == 'minkowski' else {}\n",
    "                elif self.metric == 'euclidean' or self.metric == 'l2':\n",
    "                    metric_name = 'euclidean'\n",
    "                    tree_kwargs = {'p': 2} if self.metric == 'minkowski' else {}\n",
    "                elif self.metric == 'chebyshev' or self.metric == 'infinity':\n",
    "                    metric_name = 'chebyshev'\n",
    "                    tree_kwargs = {}\n",
    "                elif self.metric == 'minkowski':\n",
    "                    metric_name = 'minkowski'\n",
    "                    tree_kwargs = {'p': self.p}\n",
    "                else:\n",
    "                    metric_name = self.metric\n",
    "                    tree_kwargs = {}\n",
    "                \n",
    "                if tree_kwargs:\n",
    "                    self.tree_ = BallTree(X, leaf_size=self.leaf_size, \n",
    "                                         metric=metric_name, **tree_kwargs)\n",
    "                else:\n",
    "                    self.tree_ = BallTree(X, leaf_size=self.leaf_size, \n",
    "                                         metric=metric_name)\n",
    "                    \n",
    "                self.tree_type_ = 'ball_tree'\n",
    "                \n",
    "            except (ValueError, TypeError) as e:\n",
    "                print(f\"BallTree не поддерживает метрику {self.metric}: {e}\")\n",
    "                print(\"Используем brute force...\")\n",
    "                self.tree_ = None\n",
    "                self.tree_type_ = 'brute'\n",
    "                \n",
    "        elif selected_algorithm == 'brute' or not hasattr(self, 'tree_'):\n",
    "            self.tree_ = None\n",
    "            self.tree_type_ = 'brute'\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        \n",
    "        self._build_tree(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def kneighbors(self, X, n_neighbors=None, return_distance=True):\n",
    "        check_is_fitted(self, ['X_', 'y_', 'tree_type_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "        elif n_neighbors <= 0:\n",
    "            raise ValueError(\"n_neighbors должен быть положительным числом\")\n",
    "        \n",
    "        if n_neighbors > len(self.X_):\n",
    "            raise ValueError(\n",
    "                f\"n_neighbors ({n_neighbors}) не может быть больше \"\n",
    "                f\"количества обучающих образцов ({len(self.X_)})\"\n",
    "            )\n",
    "        \n",
    "        if self.tree_type_ in ['kd_tree', 'ball_tree'] and self.tree_ is not None:\n",
    "            try:\n",
    "                distances, indices = self.tree_.query(\n",
    "                    X, \n",
    "                    k=n_neighbors,\n",
    "                    return_distance=return_distance\n",
    "                )\n",
    "                if n_neighbors == 1:\n",
    "                    distances = distances.reshape(-1, 1)\n",
    "                    indices = indices.reshape(-1, 1)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при поиске соседей с деревом: {e}\")\n",
    "                print(\"Переключаюсь на brute force...\")\n",
    "                distances, indices = self._brute_neighbors(X, n_neighbors)\n",
    "        else: \n",
    "            distances, indices = self._brute_neighbors(X, n_neighbors)\n",
    "        \n",
    "        if return_distance:\n",
    "            return distances, indices\n",
    "        return indices\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        distances, indices = self.kneighbors(X, return_distance=True)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            neighbor_indices = indices[i]\n",
    "            neighbor_distances = distances[i]\n",
    "            neighbor_labels = self.y_[neighbor_indices]\n",
    "            \n",
    "            if self.weights == 'uniform':\n",
    "                votes = Counter(neighbor_labels)\n",
    "                pred = votes.most_common(1)[0][0]\n",
    "                \n",
    "            elif self.weights == 'distance':\n",
    "                weights_dict = {}\n",
    "                \n",
    "                zero_distance_mask = neighbor_distances == 0\n",
    "                if np.any(zero_distance_mask):\n",
    "                    zero_indices = np.where(zero_distance_mask)[0]\n",
    "                    pred = neighbor_labels[zero_indices[0]]\n",
    "                else:\n",
    "                    for dist, label in zip(neighbor_distances, neighbor_labels):\n",
    "                        weight = 1.0 / (dist + 1e-10) \n",
    "                        weights_dict[label] = weights_dict.get(label, 0) + weight\n",
    "                    \n",
    "                    pred = max(weights_dict.items(), key=lambda x: x[1])[0]\n",
    "                    \n",
    "            else:\n",
    "                raise ValueError(f\"Неизвестный метод взвешивания: {self.weights}\")\n",
    "            \n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        distances, indices = self.kneighbors(X, return_distance=True)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        proba = np.zeros((n_samples, self.n_classes_))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            neighbor_indices = indices[i]\n",
    "            neighbor_distances = distances[i]\n",
    "            neighbor_labels = self.y_[neighbor_indices]\n",
    "            \n",
    "            if self.weights == 'uniform':\n",
    "                votes = Counter(neighbor_labels)\n",
    "                for label, count in votes.items():\n",
    "                    idx = np.where(self.classes_ == label)[0][0]\n",
    "                    proba[i, idx] = count / len(neighbor_labels)\n",
    "                    \n",
    "            elif self.weights == 'distance':\n",
    "                total_weight = 0\n",
    "                weights_dict = {}\n",
    "                \n",
    "                zero_distance_mask = neighbor_distances == 0\n",
    "                if np.any(zero_distance_mask):\n",
    "                    zero_indices = np.where(zero_distance_mask)[0]\n",
    "                    label = neighbor_labels[zero_indices[0]]\n",
    "                    idx = np.where(self.classes_ == label)[0][0]\n",
    "                    proba[i, idx] = 1.0\n",
    "                    continue\n",
    "                \n",
    "                for dist, label in zip(neighbor_distances, neighbor_labels):\n",
    "                    weight = 1.0 / (dist + 1e-10)\n",
    "                    weights_dict[label] = weights_dict.get(label, 0) + weight\n",
    "                    total_weight += weight\n",
    "                \n",
    "                if total_weight > 0:\n",
    "                    for label, weight in weights_dict.items():\n",
    "                        idx = np.where(self.classes_ == label)[0][0]\n",
    "                        proba[i, idx] = weight / total_weight\n",
    "        \n",
    "        return proba\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf94d",
   "metadata": {},
   "source": [
    "Проверим работоспособность этого класса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c648f0",
   "metadata": {},
   "source": [
    "Повторим все действия снова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403f908",
   "metadata": {},
   "source": [
    "Сначала с простым бейзлайном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59275606",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dummies = pd.get_dummies(diabetes_df['gender'], drop_first=True)\n",
    "smoking_history_dummies = pd.get_dummies(diabetes_df['smoking_history'], drop_first=True)\n",
    "onehot_diabetes_df = pd.concat([diabetes_df, gender_dummies, smoking_history_dummies], axis=1)\n",
    "\n",
    "onehot_diabetes_df.drop(['gender', 'smoking_history'], axis=1, inplace=True)\n",
    "diabetes_X = onehot_diabetes_df.drop('diabetes', axis=1)\n",
    "diabetes_y = onehot_diabetes_df['diabetes']\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(\n",
    "    diabetes_X,\n",
    "    diabetes_y,\n",
    "    test_size=0.2,\n",
    "    stratify=diabetes_y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d76fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LabKNeighborsClassifier()\n",
    "\n",
    "optimal_models = {}      \n",
    "optimal_thresholds = {}\n",
    "optimal_fold_scores = {}\n",
    "\n",
    "for beta in [1, 2, 3]:\n",
    "    optimal_models[f'f{beta}'], optimal_thresholds[f'f{beta}'], optimal_fold_scores[f'f{beta}'] = find_optimal_threshhold_cv(\n",
    "        model,\n",
    "        diabetes_X_train,\n",
    "        diabetes_y_train,\n",
    "        cv=5,\n",
    "        f_beta=beta,\n",
    "        report=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bb0c0",
   "metadata": {},
   "source": [
    "Проведем замеры на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_score in [1, 2, 3]:\n",
    "    model = optimal_models[f'f{f_score}']\n",
    "    threshold = optimal_thresholds[f'f{f_score}']\n",
    "    \n",
    "    y_prob_test = model.predict_proba(diabetes_X_test)[:, 1]\n",
    "    y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== Test Model f{f_score} ===\")\n",
    "    print(classification_report(diabetes_y_test, y_pred_test))\n",
    "    print(f\"f1-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=1):.4f}\")\n",
    "    print(f\"f2-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=2):.4f}\")\n",
    "    print(f\"f3-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=3):.4f}\")\n",
    "    print(f\"f{f_score}-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=f_score):.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ecdda",
   "metadata": {},
   "source": [
    "Вывод: результат оказался таким же как и в KNeighborsClassifier из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d874f7",
   "metadata": {},
   "source": [
    "Теперь улучшим бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3904b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X = diabetes_df.drop('diabetes', axis=1)\n",
    "diabetes_y = diabetes_df['diabetes']\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(\n",
    "    diabetes_X,\n",
    "    diabetes_y,\n",
    "    test_size=0.2,\n",
    "    stratify=diabetes_y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "diabetes_train_df = pd.DataFrame(diabetes_X_train, columns=diabetes_X.columns)\n",
    "diabetes_train_df['diabetes'] = diabetes_y_train\n",
    "\n",
    "diabetes_test_df = pd.DataFrame(diabetes_X_test, columns=diabetes_X.columns)\n",
    "diabetes_test_df['diabetes'] = diabetes_y_test\n",
    "\n",
    "# Удалим выбросы только для train\n",
    "diabetes_train_df = remove_outliers_iqr_by_group(diabetes_train_df, 'bmi', 'diabetes')\n",
    "\n",
    "# Создаем фичи\n",
    "diabetes_train_df = create_features(diabetes_train_df)\n",
    "diabetes_test_df = create_features(diabetes_test_df)\n",
    "\n",
    "# Удалим features, которые имеют высокую корреляцию с другими\n",
    "diabetes_train_df = drop_highly_correlated_features(diabetes_train_df)\n",
    "diabetes_test_df = diabetes_test_df[diabetes_train_df.columns]\n",
    "\n",
    "# Снова отделим target от всех остальных данных\n",
    "diabetes_X_train = diabetes_train_df.drop('diabetes', axis=1)\n",
    "diabetes_y_train = diabetes_train_df['diabetes']\n",
    "\n",
    "diabetes_X_test = diabetes_test_df.drop('diabetes', axis=1)\n",
    "diabetes_y_test = diabetes_test_df['diabetes']\n",
    "\n",
    "# Применим RobustScaler, т.к. он устойчив к выбросам\n",
    "scaler = RobustScaler()\n",
    "diabetes_X_train = pd.DataFrame(scaler.fit_transform(diabetes_X_train), columns=diabetes_X_train.columns)\n",
    "diabetes_X_test = pd.DataFrame(scaler.transform(diabetes_X_test), columns=diabetes_X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3b8cc",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'f1' : {'n_neighbors': 7, 'weights': 'uniform', 'p': 2, 'metric': 'manhattan'},\n",
    "    'f2' : {'n_neighbors': 4, 'weights': 'distance', 'p': 1, 'metric': 'euclidean'},\n",
    "    'f3' : {'n_neighbors': 3, 'weights': 'distance', 'p': 3, 'metric': 'manhattan'}\n",
    "}\n",
    "\n",
    "def find_best_hyperparameters_cv(X, y, n_trials=10, cv=5, scoring='accuracy', n_jobs=-1):\n",
    "    def objective(trial):\n",
    "        n_neighbors = trial.suggest_int('n_neighbors', 3, 15)\n",
    "        weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "        p = trial.suggest_int('p', 1, 3)\n",
    "        metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "        \n",
    "        model = LabKNeighborsClassifier(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            p=p,\n",
    "            metric=metric,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        \n",
    "        return cross_val_score(model, X, y, cv=cv, scoring=scoring).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "for beta in [1, 2, 3]:\n",
    "    scorer = make_scorer(fbeta_score, beta=beta) \n",
    "    if not best_params.get(f'f{beta}'):\n",
    "        best_params[f'f{beta}'] = find_best_hyperparameters_cv(\n",
    "            diabetes_X_train,\n",
    "            diabetes_y_train,\n",
    "            n_trials=10,\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            scoring=scorer\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n=== Best Model f{beta} on validation ===\")\n",
    "    print(f\"Best params: {best_params[f'f{beta}']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aaf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_models = {}      \n",
    "optimal_thresholds = {}\n",
    "optimal_fold_scores = {}\n",
    "\n",
    "for beta in [1, 2, 3]:\n",
    "    for model_name in [1, 2, 3]:\n",
    "        model = LabKNeighborsClassifier(**best_params[f'f{model_name}'])\n",
    "        \n",
    "        model, threshold, fold_score = find_optimal_threshhold_cv(\n",
    "            model,\n",
    "            diabetes_X_train,\n",
    "            diabetes_y_train,\n",
    "            cv=5,\n",
    "            f_beta=beta,\n",
    "            report=True\n",
    "        )\n",
    "        if optimal_models.get(f'f{beta}'):\n",
    "            if fold_score['f_beta_score'] > optimal_fold_scores[f'f{beta}']['f_beta_score']:\n",
    "                optimal_models[f'f{beta}'] = model\n",
    "                optimal_thresholds[f'f{beta}'] = threshold\n",
    "                optimal_fold_scores[f'f{beta}'] = fold_score\n",
    "        else:\n",
    "            optimal_models[f'f{beta}'] = model\n",
    "            optimal_thresholds[f'f{beta}'] = threshold\n",
    "            optimal_fold_scores[f'f{beta}'] = fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d971098",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [1, 2, 3]:\n",
    "    print(optimal_fold_scores[f'f{beta}']['classification_report'])\n",
    "    print(f\"Best f{beta}-score: {optimal_fold_scores[f'f{beta}']['f_beta_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442bff7",
   "metadata": {},
   "source": [
    "Проведем замеры на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in [1, 2, 3]:\n",
    "    model = optimal_models[f'f{beta}']\n",
    "    threshold = optimal_thresholds[f'f{beta}']\n",
    "    \n",
    "    y_prob_test = model.predict_proba(diabetes_X_test)[:, 1]\n",
    "    y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== Test Model f{beta} ===\")\n",
    "    print(classification_report(diabetes_y_test, y_pred_test))\n",
    "    print(f\"f1-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=1):.4f}\")\n",
    "    print(f\"f2-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=2):.4f}\")\n",
    "    print(f\"f3-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=3):.4f}\")\n",
    "    print(f\"f{beta}-score: {fbeta_score(diabetes_y_test, y_pred_test, beta=beta):.4f}\")\n",
    "    print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b27625",
   "metadata": {},
   "source": [
    "Вывод: результат оказался таким же как и в KNeighborsClassifier из sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
